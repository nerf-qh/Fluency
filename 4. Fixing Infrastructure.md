# 4. Fixing Infrastructure

Imagine you are working on a microservice-based application that provides some kind of usability, implemented in a form of multiple different services and replicas working together by messaging pattern. At first everything is going smoothly, but as the system continues to grow more and more, communication between services become more complex due to convoluted dependencies. The error-handling and debugging starts to be especially problematic as there is no central coordinator to take this responsibility on itself. Whatâ€™s even worse, partial failures halt the system as it's hard to make proper rollbacks.
**What kind of orchestration and error-handling patterns would you suggest for developers in that case, to make their app easier and solve those problems?**

If just answer to question
**orchestration**: kubernetes if we talk about orchestration of services and their comminucations, restarting etc

**error-handling**:

- Use names and special classes for errors

- handle errors

- log all errors

- don't use errors for business logic

- don't allow errors to breack the whole thread until it's system vital erorr e.g. db connection

- don't handle them this way

```js
if (err) {
  console.log(err);
  return;
}
```

- handle errors on upper level to return correct results e.g. in api to solve two problems - show correct message, status code to UI\user and to log error

- Error should be not common situation and that mean devs should be able to find the error issue using logged info

And what is not asked but present in the text:
microservices are supposed to reduce complexity and make services more or less self-eficient, when one service is down others should be able to work.
Storing fital information (like users table\collection) within the service, caching.
Banal thing - documentation for the interfaces
And when service1 ask something from service2 and service2 depends on service3 and service3 fails - service1 and service2 should still work, maybe with the old version of data

Good things to avooid rollbacks with complicated systems - use canary deployments with versiong for endpoints e.g.
This way when one service fails others will be able to work with old version
Like with crilical db migrations deploys should be done in 4 steps e.g.
And ofc test, test and tests